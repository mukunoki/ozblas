# Testing info -----------------------------
# 	Date:	Mon Sep 11 23:28:15 JST 2023
# 	CPU:	model name	: AMD EPYC 7763 64-Core Processor
# 	OMP:	OMP_NUM_THREADS =  256, MKL_NUM_THREADS = 
# 	OS:	Linux a100-1.cloud.r-ccs.riken.jp 4.18.0-425.3.1.el8.x86_64 #1 SMP Wed Nov 9 20:13:27 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
# 	Host:	a100-1.cloud.r-ccs.riken.jp
# 	Compiler:	GCC 9
# 	Device[0]	NVIDIA A100-SXM4-80GB
# 	- Theoretical Peak Memory Bandwidth:	2039.0 [GB/s]
# 	- Theoretical Peak Performance (SP):	 0.0 [GFlops]
# 	- Theoretical Peak Performance (DP):	 0.0 [GFlops]
# 	- Total Gmem:	85.0 [GB]
# 	- CC:	8.0
# 	- MultiProcessorCount:	108
# 	Driver / Runtime:	12000, 12000
#	Routine:	DDOT
#	Library:	cuOzBLAS (using cuBLAS)
#	mode: performance evaluation
#	NLOOP / WLOOP:	3/2
# OzBLAS -----------------------------------
#	Work-mem size = 1.6e+10 (bytes)
#	Degree = 0
#	splitMode = 1 (0:none, 1:infSplit (warn when infSplit is failed), 3:fastSplit+infSplit)
#	FastMode = 0
#	ReproMode = 1
#	SumMode = 1 (0:GlobalFSum, 1:GlobalNearsum, 2:LocalFsum, 3:LocalFsum3)
#	UseBatchedGemm = 1
#	SplitEpsMode = 1
#	precx = 0
# BLAS parameter ---------------------------
#	tranA:	N
#	tranB:	N
# Problem setting --------------------------
#	phi = 1 (on erange-mode, [1e0,1e1))
#	dim_start:	128
#	dim_stop:	8192000
#	dim_step:	1
#	M:	range
#	N:	range
#	K:	range
#	input: initialized with erange-mode	range = 1.00 (max = 1.000e+01, min = 1.000e+00)
#	input: initialized with erange-mode	range = 1.00 (max = 1.000e+01, min = 1.000e+00)
### Warning: batchedGemm is ignored on DOT because DOT is computed by a GEMM.
# Evaluation result ------------------------
# (* shows the value at the last execution, ** shows the value of the last block at the last execution)
# M	N	K	Time[sec]	Perf[GFlops]	Perf[GB/s]	itr	*t_SpltA	*t_SpltB	*t_Comp 	*t_Sum  	*t_Other	*t_Total	*#sA	*#sB	*#sC	*Mem[GB]	GFlops(Comp)	mbk	nbk
--	128	--	3.330e-04	7.688e-04	6.150e-03	3	1.31e-04	1.25e-04	1.91e-05	2.00e-05	1.03e-05	3.05e-04	3.0	3.0	9.0	1.0e-03	1.21e-01	1	1
--	256	--	3.330e-04	1.538e-03	1.230e-02	3	1.34e-04	1.22e-04	1.91e-05	2.00e-05	1.00e-05	3.05e-04	3.0	3.0	9.0	1.1e-03	2.42e-01	1	1
--	512	--	3.333e-04	3.072e-03	2.458e-02	3	1.45e-04	1.32e-04	2.00e-05	1.88e-05	1.03e-05	3.26e-04	3.0	3.0	9.0	1.2e-03	4.60e-01	1	1
--	1024	--	3.360e-04	6.095e-03	4.876e-02	3	1.32e-04	1.48e-04	1.88e-05	1.91e-05	1.14e-05	3.29e-04	3.0	3.0	9.0	1.5e-03	9.79e-01	1	1
--	2048	--	3.427e-04	1.195e-02	9.562e-02	3	1.36e-04	1.36e-04	1.98e-05	1.91e-05	1.14e-05	3.22e-04	3.0	3.0	9.0	2.0e-03	1.86e+00	1	1
--	4096	--	3.370e-04	2.431e-02	1.944e-01	3	1.29e-04	1.34e-04	1.91e-05	1.91e-05	1.10e-05	3.12e-04	3.0	3.0	9.0	3.0e-03	3.87e+00	1	1
--	8192	--	3.366e-04	4.867e-02	3.893e-01	3	1.37e-04	1.22e-04	1.79e-05	1.81e-05	1.03e-05	3.05e-04	3.0	3.0	9.0	5.0e-03	8.25e+00	1	1
--	16384	--	3.117e-04	1.051e-01	8.410e-01	3	1.23e-04	1.22e-04	1.91e-05	1.81e-05	1.36e-05	2.96e-04	3.0	3.0	9.0	9.1e-03	1.55e+01	1	1
--	32768	--	3.160e-04	2.074e-01	1.659e+00	3	1.24e-04	1.24e-04	1.98e-05	1.79e-05	1.05e-05	2.96e-04	3.0	3.0	9.0	1.7e-02	2.98e+01	1	1
--	65536	--	3.103e-04	4.223e-01	3.379e+00	3	1.25e-04	1.23e-04	2.00e-05	1.81e-05	9.78e-06	2.96e-04	3.0	3.0	9.0	3.3e-02	5.89e+01	1	1
--	131072	--	3.157e-04	8.304e-01	6.644e+00	3	1.28e-04	1.24e-04	2.41e-05	1.81e-05	8.82e-06	3.03e-04	3.0	3.0	9.0	6.6e-02	9.80e+01	1	1
--	262144	--	3.190e-04	1.644e+00	1.315e+01	3	1.23e-04	1.23e-04	2.60e-05	1.81e-05	9.78e-06	3.00e-04	3.0	3.0	9.0	1.3e-01	1.82e+02	1	1
--	524288	--	3.404e-04	3.081e+00	2.464e+01	3	1.28e-04	1.36e-04	3.41e-05	1.79e-05	8.82e-06	3.25e-04	3.0	3.0	9.0	2.6e-01	2.77e+02	1	1
--	1048576	--	5.204e-04	4.030e+00	3.224e+01	3	2.05e-04	2.02e-04	7.20e-05	2.10e-05	9.78e-06	5.10e-04	4.0	4.0	16.0	5.2e-01	4.66e+02	1	1
--	2097152	--	7.164e-04	5.855e+00	4.684e+01	3	2.77e-04	2.83e-04	1.09e-04	2.10e-05	9.30e-06	6.99e-04	4.0	4.0	16.0	1.0e+00	6.16e+02	1	1
--	4194304	--	1.114e-03	7.530e+00	6.024e+01	3	4.25e-04	4.44e-04	2.02e-04	2.10e-05	7.87e-06	1.10e-03	4.0	4.0	16.0	2.1e+00	6.65e+02	1	1
